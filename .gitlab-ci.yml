# To use the Docker Hub docker image
# image: docker:latest
image: $CI_REGISTRY/mouse-informatics/docker:latest

variables:
   # When using dind service we need to instruct docker, to talk with the
   # daemon started inside of the service. The daemon is available with
   # a network connection instead of the default /var/run/docker.sock socket.
   #
   # The 'docker' hostname is the alias of the service container as described at
   # https://docs.gitlab.com/ee/ci/docker/using_docker_images.html#accessing-the-services
   #
   # Note that if you're using the Kubernetes executor, the variable should be set to
   # tcp://localhost:2375/ because of how the Kubernetes executor connects services
   # to the job container
   # DOCKER_HOST: tcp://localhost:2375/
   #
   # For non-Kubernetes executors, we use tcp://docker:2375/
   DOCKER_HOST: tcp://docker:2375/
   # When using dind, it's wise to use the overlayfs driver for
   # improved performance.
   DOCKER_DRIVER: overlay2
   
   # Since the docker:dind container and the runner container don’t share their root
   # filesystem, the job’s working directory can be used as a mount point for children
   # containers. For example, if you have files you want to share with a child container,
   # you may create a subdirectory under /builds/$CI_PROJECT_PATH and use it as your
   # mount point.
   MOUNT_POINT: /builds/$CI_PROJECT_PATH/mnt
   
   # For EBI you need to override the definition of CI_REGISTRY to remove the port number
   CI_REGISTRY: dockerhub.ebi.ac.uk
   CI_REGISTRY_IMAGE: $CI_REGISTRY/$CI_PROJECT_PATH

   #NOW: $(date '+%Y-%m-%d-%H-%M-%S')
   #NOW: $(date '+%Y-%m-%d')
   
   # To solve the issue with the Docker in Docker 19.03 service.
   # Logged as: GitLab.com CI jobs failing if using docker:stable-dind image
   # see: https://gitlab.com/gitlab-com/gl-infra/production/issues/982
   DOCKER_TLS_CERTDIR: ""
   SCAN_KUBERNETES_MANIFESTS: "true"


  # Use this command to look at your docker environment
  # Note: This step can be overwritten by before_script sections in specific jobs.
  #
  #before_script:
  #   - docker info

include:
  - template: Security/SAST.gitlab-ci.yml
  - template: Security/Secret-Detection.gitlab-ci.yml



stages:
#   - env
   - build
   - test
   - dev-deploy
   - dev-test
   - production-deploy
   - production-test
   - reference-deploy
   - reference-test

# env:
#   stage: env
#   script:
#     - export


build_image:
    stage: build
    services:
      - name: $CI_REGISTRY/mouse-informatics/dind:latest
        alias: docker
    except:
        - schedules
        - triggers
        - pipelines
    script:
        # - docker info
        - mkdir -p "$MOUNT_POINT"
        - echo "${CI_REGISTRY_PASSWORD}" | docker login -u "${CI_REGISTRY_USER}" --password-stdin  ${CI_REGISTRY}

        - sed -i "s|maven|${LOCAL_GITLAB_MAVEN_IMAGE}|g" Dockerfile       
        - sed -i "s|FROM amazoncorretto|FROM ${LOCAL_GITLAB_CORRETTO_IMAGE}|g" Dockerfile     
            
        - docker build -t "${CI_REGISTRY_IMAGE}":"${CI_COMMIT_SHA:0:12}" -t "${CI_REGISTRY_IMAGE}":latest .  | tee ${MOUNT_POINT}/build.log
                
        - docker push "${CI_REGISTRY_IMAGE}":"${CI_COMMIT_SHA:0:12}"  | tee ${MOUNT_POINT}/push.log
        - docker push "${CI_REGISTRY_IMAGE}":latest  | tee ${MOUNT_POINT}/push.log
       
        - docker logout ${CI_REGISTRY}

        - |
          if [[ "${DOCKER_HUB_PUSH}" == "true" ]]; then

              echo "${DOCKER_HUB_PSWD}" | docker login -u "${DOCKER_HUB_USER}" --password-stdin
              docker tag "${CI_REGISTRY_IMAGE}":"${CI_COMMIT_SHA:0:12}" "${DOCKER_HUB_USER}"/"${DOCKER_HUB_REPO}":"${CI_COMMIT_SHA:0:12}"
              docker tag "${CI_REGISTRY_IMAGE}":"${CI_COMMIT_SHA:0:12}" "${DOCKER_HUB_USER}"/"${DOCKER_HUB_REPO}":latest
              docker push "${DOCKER_HUB_USER}"/"${DOCKER_HUB_REPO}":"${CI_COMMIT_SHA:0:12}"  | tee ${MOUNT_POINT}/dockerhub-push-latest.log
              docker push "${DOCKER_HUB_USER}"/"${DOCKER_HUB_REPO}":latest  | tee ${MOUNT_POINT}/dockerhub-push-latest.log
              docker logout
          fi
    artifacts:
        paths:
            - "$MOUNT_POINT/"


sast:
  stage: test
  script:
    - echo "Running SAST scan ..."

  artifacts:
    reports:
      container_scanning: gl-sast-report.json


secret_detection:
  stage: test
  script:
    - echo "Running secret detection scan ..."

  artifacts:
    reports:
      container_scanning: gl-secret-detection-report.json



trivy_container_scanning:
  stage: test

  services:
    - name: $CI_REGISTRY/mouse-informatics/dind:latest
      alias: docker

  rules:
    - if: '$CI_BUILD_REF_NAME == "main"'
      when: on_success
      allow_failure: true

  before_script:
    - export TRIVY_VERSION=$(wget -qO - "https://api.github.com/repos/aquasecurity/trivy/releases/latest" | grep '"tag_name":' | sed -E 's/.*"v([^"]+)".*/\1/')
    - echo $TRIVY_VERSION
    - wget --no-verbose https://github.com/aquasecurity/trivy/releases/download/v${TRIVY_VERSION}/trivy_${TRIVY_VERSION}_Linux-64bit.tar.gz -O - | tar -zxvf -
    - echo "${CI_REGISTRY_PASSWORD}" | docker login -u "${CI_REGISTRY_USER}" --password-stdin  ${CI_REGISTRY}

  script:
    # Build report
    - ./trivy --cache-dir .trivycache/ image --exit-code 0 --no-progress --format template --template "@contrib/gitlab.tpl" -o gl-container-scanning-report.json "${CI_REGISTRY_IMAGE}":"${CI_COMMIT_SHA:0:12}"
    # Print report
    - ./trivy --cache-dir .trivycache/ image --exit-code 0 --no-progress --severity HIGH "${CI_REGISTRY_IMAGE}":"${CI_COMMIT_SHA:0:12}"
    # Fail on critical vulnerability
    - ./trivy --cache-dir .trivycache/ image --exit-code 1 --severity CRITICAL --no-progress "${CI_REGISTRY_IMAGE}":"${CI_COMMIT_SHA:0:12}"

    - docker logout ${CI_REGISTRY}

  cache:
    paths:
      - .trivycache/

  artifacts:
    reports:
      container_scanning: gl-container-scanning-report.json

hh-dev:
  stage: dev-deploy
  services:
    - name: $CI_REGISTRY/mouse-informatics/dind:latest
      alias: docker
  image: $CI_REGISTRY/mouse-informatics/helm-kubectl-alpine:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  script:
    # Only deploy from the MPI2 impc-production-tracker repository rather than repository forks
    - |
      if [ ! -z ${HH_KUBERNETES_ENDPOINT+set} ]; then

        apk --no-cache --update add jq curl

        kubectl config set-cluster local --server="${HH_KUBERNETES_ENDPOINT}"
        kubectl config set clusters.local.certificate-authority-data "${HH_KUBERNETES_CERTIFICATE_AUTHORITY_DATA}"
        kubectl config set-credentials ${HH_KUBERNETES_DEV_USER} --token="${HH_KUBERNETES_DEV_USER_TOKEN}"
        kubectl config set-context "${HH_KUBERNETES_DEV_NAMESPACE}" --cluster=local --user=${HH_KUBERNETES_DEV_USER} --namespace="${HH_KUBERNETES_DEV_NAMESPACE}"
        kubectl config use-context "${HH_KUBERNETES_DEV_NAMESPACE}"
        kubectl version

        #
        #
        # Substitute the "latest" image tag in your deployment template with a more specific tag
        # and record the deployment so you can rollback to this particular version.
        #

        # Need to check that the docker image corresponding to this CI_COMMIT_SHA exists in Docker Hub.
        # Scheduled turnover of the container can still run for a CI_COMMIT_SHA where the build fail to complete.

        # TOKEN=$( curl -sSLd "username=${DOCKER_HUB_USER}&password=${DOCKER_HUB_PSWD}" https://hub.docker.com/v2/users/login | jq -r ".token" )
        # JSON=$( curl -sH "Authorization: JWT $TOKEN" "https://hub.docker.com/v2/repositories/${DOCKER_HUB_USER}/${DOCKER_HUB_REPO}/tags/${CI_COMMIT_SHA:0:12}/")
        # IMAGE_TAG_NAME=$(echo $JSON | jq  -r '.name')

        REGISTRY_JSON=$( curl --header "PRIVATE-TOKEN: ${GITLAB_API_ACCESS_TOKEN}" "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/registry/repositories/")
        REGISTRY_REPOSITORY_ID=$(echo $REGISTRY_JSON | jq '.[0].id')

        JSON=$( curl --header "PRIVATE-TOKEN: ${GITLAB_API_ACCESS_TOKEN}" "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/registry/repositories/${REGISTRY_REPOSITORY_ID}/tags/${CI_COMMIT_SHA:0:12}/")
        IMAGE_TAG_NAME=$(echo $JSON | jq  -r '.name')

        if [ "$IMAGE_TAG_NAME" = "${CI_COMMIT_SHA:0:12}" ]; then
            # Substitute the "latest" image tag in your deployment template
            sed -i "s/orthology-api-mirror:latest/orthology-api-mirror:${CI_COMMIT_SHA:0:12}/g" kube/wp/dev/api-service/api-service-deployment.yaml
        else
            # DO NOT push out the latest tag to ensure rollback is possible.
            exit 1
        fi


        sed -i "s/STRING_REPLACED_DURING_REDEPLOY/$(date)/g" kube/wp/dev/api-service/api-service-deployment.yaml

        if kubectl apply -f kube/wp/dev/api-service/api-service-deployment.yaml --record | grep -q unchanged; then
            echo "=> Patching deployment to force image update."
            kubectl patch -f kube/wp/dev/api-service/api-service-deployment.yaml --record -p "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"ci-last-updated\":\"$(date +'%s')\"}}}}}"
        else
            echo "=> Deployment apply has changed the object, no need to force image update."
        fi
        #
        #
        # Log the status of the application deployment
        #
        kubectl rollout status -f kube/wp/dev/api-service/api-service-deployment.yaml
        kubectl get pod,deployment,rs,svc,ing
      fi

hx-dev:
  stage: dev-deploy
  services:
    - name: $CI_REGISTRY/mouse-informatics/dind:latest
      alias: docker
  image: $CI_REGISTRY/mouse-informatics/helm-kubectl-alpine:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  script:
    # Only deploy from the MPI2 impc-production-tracker repository rather than repository forks
    - |
      if [ ! -z ${HX_KUBERNETES_ENDPOINT+set} ]; then

        apk --no-cache --update add jq curl

        kubectl config set-cluster local --server="${HX_KUBERNETES_ENDPOINT}"
        kubectl config set clusters.local.certificate-authority-data "${HX_KUBERNETES_CERTIFICATE_AUTHORITY_DATA}"
        kubectl config set-credentials ${HX_KUBERNETES_DEV_USER} --token="${HX_KUBERNETES_DEV_USER_TOKEN}"
        kubectl config set-context "${HX_KUBERNETES_DEV_NAMESPACE}" --cluster=local --user=${HX_KUBERNETES_DEV_USER} --namespace="${HX_KUBERNETES_DEV_NAMESPACE}"
        kubectl config use-context "${HX_KUBERNETES_DEV_NAMESPACE}"
        kubectl version

        #
        #
        # Substitute the "latest" image tag in your deployment template with a more specific tag
        # and record the deployment so you can rollback to this particular version.
        #

        # Need to check that the docker image corresponding to this CI_COMMIT_SHA exists in Docker Hub.
        # Scheduled turnover of the container can still run for a CI_COMMIT_SHA where the build fail to complete.

        # TOKEN=$( curl -sSLd "username=${DOCKER_HUB_USER}&password=${DOCKER_HUB_PSWD}" https://hub.docker.com/v2/users/login | jq -r ".token" )
        # JSON=$( curl -sH "Authorization: JWT $TOKEN" "https://hub.docker.com/v2/repositories/${DOCKER_HUB_USER}/${DOCKER_HUB_REPO}/tags/${CI_COMMIT_SHA:0:12}/")
        # IMAGE_TAG_NAME=$(echo $JSON | jq  -r '.name')

        REGISTRY_JSON=$( curl --header "PRIVATE-TOKEN: ${GITLAB_API_ACCESS_TOKEN}" "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/registry/repositories/")
        REGISTRY_REPOSITORY_ID=$(echo $REGISTRY_JSON | jq '.[0].id')

        JSON=$( curl --header "PRIVATE-TOKEN: ${GITLAB_API_ACCESS_TOKEN}" "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/registry/repositories/${REGISTRY_REPOSITORY_ID}/tags/${CI_COMMIT_SHA:0:12}/")
        IMAGE_TAG_NAME=$(echo $JSON | jq  -r '.name')

        if [ "$IMAGE_TAG_NAME" = "${CI_COMMIT_SHA:0:12}" ]; then
            # Substitute the "latest" image tag in your deployment template
            sed -i "s/orthology-api-mirror:latest/orthology-api-mirror:${CI_COMMIT_SHA:0:12}/g" kube/wp/dev/api-service/api-service-deployment.yaml
        else
            # DO NOT push out the latest tag to ensure rollback is possible.
            exit 1
        fi


        sed -i "s/STRING_REPLACED_DURING_REDEPLOY/$(date)/g" kube/wp/dev/api-service/api-service-deployment.yaml

        if kubectl apply -f kube/wp/dev/api-service/api-service-deployment.yaml --record | grep -q unchanged; then
            echo "=> Patching deployment to force image update."
            kubectl patch -f kube/wp/dev/api-service/api-service-deployment.yaml --record -p "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"ci-last-updated\":\"$(date +'%s')\"}}}}}"
        else
            echo "=> Deployment apply has changed the object, no need to force image update."
        fi
        #
        #
        # Log the status of the application deployment
        #
        kubectl rollout status -f kube/wp/dev/api-service/api-service-deployment.yaml
        kubectl get pod,deployment,rs,svc,ing
      fi

hh-dev-test:
  image: $CI_REGISTRY/mouse-informatics/ubuntu:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  stage: dev-test
  before_script:
    - apt-get update && apt-get install -y curl && apt-get clean && rm -rf /var/lib/apt/lists/*
  script:

    # Establish a data directory
    - mkdir -p "$MOUNT_POINT"
    - cd "$MOUNT_POINT"

    - source "$CI_PROJECT_DIR"/scripts/service_test.sh --hh-dev | tee ${MOUNT_POINT}/hh-dev-test.log


  artifacts:
    paths:
      - "$MOUNT_POINT/"

hx-dev-test:
  image: $CI_REGISTRY/mouse-informatics/ubuntu:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  stage: dev-test
  before_script:
    - apt-get update && apt-get install -y curl && apt-get clean && rm -rf /var/lib/apt/lists/*
  script:

    # Establish a data directory
    - mkdir -p "$MOUNT_POINT"
    - cd "$MOUNT_POINT"

    - source "$CI_PROJECT_DIR"/scripts/service_test.sh --hx-dev | tee ${MOUNT_POINT}/hx-dev-test.log


  artifacts:
    paths:
      - "$MOUNT_POINT/"

hh-production:
  stage: production-deploy
  image: $CI_REGISTRY/mouse-informatics/helm-kubectl-alpine:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  script:
    # Only deploy from the MPI2 impc-production-tracker repository rather than repository forks
    - |
      if [ ! -z ${HH_KUBERNETES_ENDPOINT+set} ]; then

        kubectl config set-cluster local --server="${HH_KUBERNETES_ENDPOINT}"
        kubectl config set clusters.local.certificate-authority-data "${HH_KUBERNETES_CERTIFICATE_AUTHORITY_DATA}"
        kubectl config set-credentials ${HH_KUBERNETES_USER} --token="${HH_KUBERNETES_USER_TOKEN}"
        kubectl config set-context "${HH_KUBERNETES_NAMESPACE}" --cluster=local --user=${HH_KUBERNETES_USER} --namespace="${HH_KUBERNETES_NAMESPACE}"
        kubectl config use-context "${HH_KUBERNETES_NAMESPACE}"
        kubectl version

        #
        #
        # Substitute the "latest" image tag in your deployment template with a more specific tag
        # and record the deployment so you can rollback to this particular version.
        #
        sed -i "s/STRING_REPLACED_DURING_REDEPLOY/$(date)/g" kube/wp/production/api-service/api-service-deployment.yaml

        if kubectl apply -f kube/wp/production/api-service/api-service-deployment.yaml --record | grep -q unchanged; then
            echo "=> Patching deployment to force image update."
            kubectl patch -f kube/wp/production/api-service/api-service-deployment.yaml --record -p "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"ci-last-updated\":\"$(date +'%s')\"}}}}}"
        else
            echo "=> Deployment apply has changed the object, no need to force image update."
        fi
        #
        #
        # Log the status of the application deployment
        #
        kubectl rollout status -f kube/wp/production/api-service/api-service-deployment.yaml
        kubectl get pod,deployment,rs,svc,ing
      fi

hx-production:
  stage: production-deploy
  image: $CI_REGISTRY/mouse-informatics/helm-kubectl-alpine:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  script:
    # Only deploy from the MPI2 impc-production-tracker repository rather than repository forks
    - |
      if [ ! -z ${HX_KUBERNETES_ENDPOINT+set} ]; then

        kubectl config set-cluster local --server="${HX_KUBERNETES_ENDPOINT}"
        kubectl config set clusters.local.certificate-authority-data "${HX_KUBERNETES_CERTIFICATE_AUTHORITY_DATA}"
        kubectl config set-credentials ${HX_KUBERNETES_USER} --token="${HX_KUBERNETES_USER_TOKEN}"
        kubectl config set-context "${HX_KUBERNETES_NAMESPACE}" --cluster=local --user=${HX_KUBERNETES_USER} --namespace="${HX_KUBERNETES_NAMESPACE}"
        kubectl config use-context "${HX_KUBERNETES_NAMESPACE}"
        kubectl version

        #
        #
        # Substitute the "latest" image tag in your deployment template with a more specific tag
        # and record the deployment so you can rollback to this particular version.
        #
        sed -i "s/STRING_REPLACED_DURING_REDEPLOY/$(date)/g" kube/wp/production/api-service/api-service-deployment.yaml

        if kubectl apply -f kube/wp/production/api-service/api-service-deployment.yaml --record | grep -q unchanged; then
            echo "=> Patching deployment to force image update."
            kubectl patch -f kube/wp/production/api-service/api-service-deployment.yaml --record -p "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"ci-last-updated\":\"$(date +'%s')\"}}}}}"
        else
            echo "=> Deployment apply has changed the object, no need to force image update."
        fi
        #
        #
        # Log the status of the application deployment
        #
        kubectl rollout status -f kube/wp/production/api-service/api-service-deployment.yaml
        kubectl get pod,deployment,rs,svc,ing
      fi

hh-production-test:
  image: $CI_REGISTRY/mouse-informatics/ubuntu:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  stage: production-test
  before_script:
    - apt-get update && apt-get install -y curl && apt-get clean && rm -rf /var/lib/apt/lists/*
  script:

    # Establish a data directory
    - mkdir -p "$MOUNT_POINT"
    - cd "$MOUNT_POINT"

    - source "$CI_PROJECT_DIR"/scripts/service_test.sh --hh-production | tee ${MOUNT_POINT}/hh-dev-test.log


  artifacts:
    paths:
      - "$MOUNT_POINT/"

hx-production-test:
  image: $CI_REGISTRY/mouse-informatics/ubuntu:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  stage: production-test
  before_script:
    - apt-get update && apt-get install -y curl && apt-get clean && rm -rf /var/lib/apt/lists/*
  script:

    # Establish a data directory
    - mkdir -p "$MOUNT_POINT"
    - cd "$MOUNT_POINT"

    - source "$CI_PROJECT_DIR"/scripts/service_test.sh --hx-production | tee ${MOUNT_POINT}/hh-dev-test.log

  artifacts:
    paths:
      - "$MOUNT_POINT/"


hh-reference-deploy:
  stage: reference-deploy
  # Use an image with helm v2.14.3, kubectl v1.15.2, alpine 3.10
  # rancher/hyperkube:v1.15.3-rancher1 installed on the hh cluster
  image: $CI_REGISTRY/mouse-informatics/helm-kubectl-alpine:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  script:
    - echo ${NOW}
    #
    - kubectl config set-cluster local --server="${HH_KUBERNETES_ENDPOINT}"
    - kubectl config set clusters.local.certificate-authority-data "${HH_KUBERNETES_CERTIFICATE_AUTHORITY_DATA}"
    - kubectl config set-credentials ${HH_KUBERNETES_REFERENCE_USER} --token="${HH_KUBERNETES_REFERENCE_USER_TOKEN}"
    - kubectl config set-context "${HH_KUBERNETES_REFERENCE_NAMESPACE}" --cluster=local --user=${HH_KUBERNETES_REFERENCE_USER} --namespace="${HH_KUBERNETES_REFERENCE_NAMESPACE}"
    - kubectl config use-context "${HH_KUBERNETES_REFERENCE_NAMESPACE}"
    - kubectl version
    #
    - sed -i "s/latest/${NOW}/g" kube/wp/reference/api-service/api-service-deployment.yaml
    - sed -i "s/STRING_REPLACED_DURING_REDEPLOY/$(date)/g" kube/wp/reference/api-service/api-service-deployment.yaml

    - |
      if kubectl apply -f  kube/wp/reference/api-service/api-service-deployment.yaml --record | grep -q unchanged; then
          echo "=> Patching deployment to force image update."
          kubectl patch -f  kube/wp/reference/api-service/api-service-deployment.yaml --record -p "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"ci-last-updated\":\"$(date +'%s')\"}}}}}"
      else
          echo "=> Deployment apply has changed the object, no need to force image update."
      fi


    - kubectl rollout status -f  kube/wp/reference/api-service/api-service-deployment.yaml
    - kubectl get pod,deployment,rs



hx-reference-deploy:
  stage: reference-deploy
  # Use an image with helm v2.14.3, kubectl v1.15.2, alpine 3.10
  # rancher/hyperkube:v1.15.3-rancher1 installed on the hh cluster
  image: $CI_REGISTRY/mouse-informatics/helm-kubectl-alpine:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  script:
    - echo ${NOW}
    #
    - kubectl config set-cluster local --server="${HX_KUBERNETES_ENDPOINT}"
    - kubectl config set clusters.local.certificate-authority-data "${HX_KUBERNETES_CERTIFICATE_AUTHORITY_DATA}"
    - kubectl config set-credentials ${HX_KUBERNETES_REFERENCE_USER} --token="${HX_KUBERNETES_REFERENCE_USER_TOKEN}"
    - kubectl config set-context "${HX_KUBERNETES_REFERENCE_NAMESPACE}" --cluster=local --user=${HX_KUBERNETES_REFERENCE_USER} --namespace="${HX_KUBERNETES_REFERENCE_NAMESPACE}"
    - kubectl config use-context "${HX_KUBERNETES_REFERENCE_NAMESPACE}"
    - kubectl version
    #
    - sed -i "s/latest/${NOW}/g" kube/wp/reference/api-service/api-service-deployment.yaml
    - sed -i "s/STRING_REPLACED_DURING_REDEPLOY/$(date)/g" kube/wp/reference/api-service/api-service-deployment.yaml

    - |
      if kubectl apply -f  kube/wp/reference/api-service/api-service-deployment.yaml --record | grep -q unchanged; then
          echo "=> Patching deployment to force image update."
          kubectl patch -f  kube/wp/reference/api-service/api-service-deployment.yaml --record -p "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"ci-last-updated\":\"$(date +'%s')\"}}}}}"
      else
          echo "=> Deployment apply has changed the object, no need to force image update."
      fi


    - kubectl rollout status -f  kube/wp/reference/api-service/api-service-deployment.yaml
    - kubectl get pod,deployment,rs

reference-test:
  image: $CI_REGISTRY/mouse-informatics/ubuntu:latest
  rules:
    - if: '$CI_PROJECT_NAMESPACE == "mouse-informatics" && $CI_BUILD_REF_NAME == "main"'
  stage: reference-test
  before_script:
    - apt-get update && apt-get install -y curl && apt-get clean && rm -rf /var/lib/apt/lists/*
  script:
    # Establish a data directory
    - mkdir -p "$MOUNT_POINT"
    - cd "$MOUNT_POINT"

    - source "$CI_PROJECT_DIR"/scripts/service_test.sh --reference | tee ${MOUNT_POINT}/production-test.log

  artifacts:
    paths:
      - "$MOUNT_POINT/"




